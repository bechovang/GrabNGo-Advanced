# H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t YOLO Pose tr√™n Windows v·ªõi GPU

## üìã Y√™u c·∫ßu h·ªá th·ªëng

### Ph·∫ßn c·ª©ng

- **GPU NVIDIA** v·ªõi CUDA support (GTX/RTX series)
- RAM: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB+)
- ·ªî c·ª©ng: T·ªëi thi·ªÉu 10GB tr·ªëng

### Ph·∫ßn m·ªÅm

- Windows 10/11
- NVIDIA GPU Driver (phi√™n b·∫£n m·ªõi nh·∫•t)
- Python 3.11 ho·∫∑c 3.12 (‚ö†Ô∏è **KH√îNG d√πng Python 3.13**)

---

## üîç B∆∞·ªõc 1: Ki·ªÉm tra GPU v√† CUDA

### 1.1. Ki·ªÉm tra GPU ƒë√£ c√†i driver ch∆∞a

M·ªü **Command Prompt** ho·∫∑c **PowerShell**, ch·∫°y:

```bash
nvidia-smi
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |
...
```

‚úÖ N·∫øu th·∫•y th√¥ng tin GPU ‚Üí OK, chuy·ªÉn b∆∞·ªõc 2

‚ùå N·∫øu b√°o l·ªói `'nvidia-smi' is not recognized`:

1. T·∫£i driver NVIDIA t·∫°i: https://www.nvidia.com/Download/index.aspx
2. C√†i ƒë·∫∑t v√† kh·ªüi ƒë·ªông l·∫°i m√°y
3. Ch·∫°y l·∫°i `nvidia-smi`

### 1.2. Ghi nh·ªõ CUDA Version

T·ª´ k·∫øt qu·∫£ `nvidia-smi`, ghi nh·ªõ **CUDA Version** (v√≠ d·ª•: 12.7, 12.1, 11.8, v.v.)

---

## üêç B∆∞·ªõc 2: C√†i ƒë·∫∑t Python 3.11

### 2.1. Ki·ªÉm tra Python hi·ªán t·∫°i

```bash
python --version
```

‚ö†Ô∏è **Quan tr·ªçng:** PyTorch ch∆∞a h·ªó tr·ª£ ƒë·∫ßy ƒë·ªß Python 3.13 v·ªõi CUDA builds. B·∫°n PH·∫¢I d√πng Python 3.11 ho·∫∑c 3.12.

### 2.2. T·∫£i v√† c√†i Python 3.11 (n·∫øu c·∫ßn)

1. Truy c·∫≠p: https://www.python.org/downloads/release/python-31110/
2. K√©o xu·ªëng ph·∫ßn **Files**, t·∫£i:

   - **Windows installer (64-bit)** - `python-3.11.10-amd64.exe`

3. Ch·∫°y file c√†i ƒë·∫∑t:

   - ‚úÖ **QUAN TR·ªåNG:** Ch·ªçn "**Add python.exe to PATH**"
   - Ch·ªçn "**Install Now**"
   - ƒê·ª£i c√†i ƒë·∫∑t ho√†n t·∫•t

4. **Kh·ªüi ƒë·ªông l·∫°i Command Prompt** (b·∫Øt bu·ªôc!)

5. Ki·ªÉm tra:

```bash
python --version
# Ho·∫∑c
py -3.11 --version
```

---

## üìÅ B∆∞·ªõc 3: T·∫°o th∆∞ m·ª•c d·ª± √°n v√† Virtual Environment

### 3.1. T·∫°o th∆∞ m·ª•c d·ª± √°n

```bash
# T·∫°o th∆∞ m·ª•c
mkdir C:\YoloPose
cd C:\YoloPose
```

### 3.2. T·∫°o Virtual Environment

```bash
# N·∫øu d√πng Python 3.11 m·∫∑c ƒë·ªãnh
python -m venv venv

# N·∫øu c√≥ nhi·ªÅu phi√™n b·∫£n Python
py -3.11 -m venv venv
```

### 3.3. K√≠ch ho·∫°t Virtual Environment

```bash
# Windows Command Prompt
venv\Scripts\activate

# Windows PowerShell (n·∫øu g·∫∑p l·ªói permission)
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
venv\Scripts\Activate.ps1
```

**Sau khi k√≠ch ho·∫°t, b·∫°n s·∫Ω th·∫•y `(venv)` ·ªü ƒë·∫ßu d√≤ng l·ªánh:**

```
(venv) C:\YoloPose>
```

---

## üîß B∆∞·ªõc 4: C√†i ƒë·∫∑t PyTorch v·ªõi CUDA

### 4.1. C·∫≠p nh·∫≠t pip

```bash
python -m pip install --upgrade pip
```

### 4.2. C√†i PyTorch v·ªõi CUDA

**D·ª±a v√†o CUDA version t·ª´ B∆∞·ªõc 1.2:**

#### CUDA 12.x (12.1, 12.4, 12.7):

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

#### CUDA 11.8:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

‚è≥ **L∆∞u √Ω:** File PyTorch kho·∫£ng 2-3GB, c·∫ßn th·ªùi gian t·∫£i.

### 4.3. Ki·ªÉm tra c√†i ƒë·∫∑t PyTorch

T·∫°o file `check_gpu.py`:

```python
import torch

print("=" * 60)
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"cuDNN version: {torch.backends.cudnn.version()}")
print(f"Number of GPUs: {torch.cuda.device_count()}")

if torch.cuda.is_available():
    print(f"GPU 0: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("‚ö†Ô∏è WARNING: CUDA not available! Check installation.")
print("=" * 60)
```

Ch·∫°y:

```bash
python check_gpu.py
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

```
============================================================
PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
cuDNN version: 90100
Number of GPUs: 1
GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU
GPU Memory: 8.00 GB
============================================================
```

‚úÖ **QUAN TR·ªåNG:**

- Version ph·∫£i c√≥ `+cu124` ho·∫∑c `+cu118` (KH√îNG ph·∫£i `+cpu`)
- `CUDA available` ph·∫£i l√† `True`

‚ùå N·∫øu th·∫•y `CUDA available: False`:

- G·ª° c√†i ƒë·∫∑t: `pip uninstall torch torchvision torchaudio -y`
- C√†i l·∫°i v·ªõi ƒë√∫ng CUDA version
- Ki·ªÉm tra driver NVIDIA

---

## üì¶ B∆∞·ªõc 5: C√†i ƒë·∫∑t Ultralytics YOLO

```bash
pip install ultralytics
pip install opencv-python
pip install numpy
pip install pillow
```

---

## üß™ B∆∞·ªõc 6: Test YOLO Pose

### 6.1. Test c∆° b·∫£n v·ªõi ·∫£nh

T·∫°o file `test_image.py`:

```python
from ultralytics import YOLO
import torch

# Ki·ªÉm tra GPU
print(f"Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# Load model
print("\nLoading YOLO Pose model...")
model = YOLO('yolov8n-pose.pt')

# Predict v·ªõi ·∫£nh t·ª´ URL
print("\nRunning prediction on sample image...")
results = model.predict(
    source='https://ultralytics.com/images/bus.jpg',
    device=0,  # GPU
    save=True,
    show=True,
    conf=0.5
)

print("\n‚úÖ Done! Check 'runs/pose/predict' folder for results")
```

Ch·∫°y:

```bash
python test_image.py
```

### 6.2. Test v·ªõi webcam

T·∫°o file `test_webcam.py`:

```python
from ultralytics import YOLO
import torch
import cv2

def main():
    # Ki·ªÉm tra GPU
    if not torch.cuda.is_available():
        print("‚ö†Ô∏è WARNING: GPU not available, using CPU")
        device = 'cpu'
    else:
        device = 0
        print(f"‚úÖ Using GPU: {torch.cuda.get_device_name(0)}")

    # Load model
    print("Loading YOLO Pose model...")
    model = YOLO('yolov8n-pose.pt')

    # M·ªü webcam
    print("Opening webcam...")
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("‚ùå ERROR: Cannot open webcam")
        return

    print("‚úÖ Webcam opened successfully")
    print("Press 'q' to quit")

    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Failed to read frame")
            break

        # D·ª± ƒëo√°n
        results = model(frame, device=device, verbose=False, conf=0.5)

        # V·∫Ω k·∫øt qu·∫£
        annotated_frame = results[0].plot()

        # Hi·ªÉn th·ªã th√¥ng tin
        frame_count += 1
        cv2.putText(
            annotated_frame,
            f'Frame: {frame_count}',
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 255, 0),
            2
        )

        # Hi·ªÉn th·ªã
        cv2.imshow('YOLO Pose Detection - Press Q to quit', annotated_frame)

        # Tho√°t khi nh·∫•n 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print(f"\n‚úÖ Processed {frame_count} frames")

if __name__ == '__main__':
    main()
```

Ch·∫°y:

```bash
python test_webcam.py
```

### 6.3. Test v·ªõi video file

T·∫°o file `test_video.py`:

```python
from ultralytics import YOLO
import torch

# Load model
model = YOLO('yolov8n-pose.pt')

# Predict v·ªõi video
print("Processing video...")
results = model.predict(
    source='your_video.mp4',  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n video c·ªßa b·∫°n
    device=0,
    save=True,
    show=False,
    conf=0.5,
    verbose=True
)

print("‚úÖ Done! Check 'runs/pose/predict' folder")
```

---

## üéØ B∆∞·ªõc 7: Code ho√†n ch·ªânh v·ªõi x·ª≠ l√Ω Keypoints

T·∫°o file `pose_analysis.py`:

```python
from ultralytics import YOLO
import cv2
import numpy as np

# T√™n c√°c keypoints (COCO format - 17 keypoints)
KEYPOINT_NAMES = [
    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
]

def analyze_pose(image_path):
    # Load model
    model = YOLO('yolov8n-pose.pt')

    # Predict
    results = model(image_path, device=0)

    # X·ª≠ l√Ω k·∫øt qu·∫£
    for result in results:
        keypoints = result.keypoints

        if keypoints is not None and len(keypoints) > 0:
            # L·∫•y t·ªça ƒë·ªô v√† confidence
            xy = keypoints.xy.cpu().numpy()  # Shape: (num_people, 17, 2)
            conf = keypoints.conf.cpu().numpy()  # Shape: (num_people, 17)

            # X·ª≠ l√Ω t·ª´ng ng∆∞·ªùi
            for person_idx in range(xy.shape[0]):
                print(f"\n{'='*60}")
                print(f"Person {person_idx + 1}:")
                print(f"{'='*60}")

                person_kpts = xy[person_idx]
                person_conf = conf[person_idx]

                # In th√¥ng tin t·ª´ng keypoint
                for kpt_idx, kpt_name in enumerate(KEYPOINT_NAMES):
                    x, y = person_kpts[kpt_idx]
                    confidence = person_conf[kpt_idx]

                    if confidence > 0.5:  # Ch·ªâ in keypoints c√≥ confidence cao
                        print(f"  {kpt_name:15s}: ({x:6.1f}, {y:6.1f}) - conf: {confidence:.2f}")

        # Hi·ªÉn th·ªã v√† l∆∞u k·∫øt qu·∫£
        result.show()
        result.save('output_pose_analysis.jpg')

if __name__ == '__main__':
    # Test v·ªõi ·∫£nh
    analyze_pose('https://ultralytics.com/images/bus.jpg')
```

---

## üìä C√°c model YOLO Pose c√≥ s·∫µn

| Model             | Size   | Speed     | Accuracy   | Use Case             |
| ----------------- | ------ | --------- | ---------- | -------------------- |
| `yolov8n-pose.pt` | Nano   | R·∫•t nhanh | Trung b√¨nh | Webcam real-time     |
| `yolov8s-pose.pt` | Small  | Nhanh     | T·ªët        | C√¢n b·∫±ng             |
| `yolov8m-pose.pt` | Medium | TB        | T·ªët        | ƒê·ªô ch√≠nh x√°c cao h∆°n |
| `yolov8l-pose.pt` | Large  | Ch·∫≠m      | R·∫•t t·ªët    | Video ch·∫•t l∆∞·ª£ng cao |
| `yolov8x-pose.pt` | XLarge | R·∫•t ch·∫≠m  | T·ªët nh·∫•t   | Nghi√™n c·ª©u           |

**ƒê·ªÉ thay ƒë·ªïi model:**

```python
model = YOLO('yolov8s-pose.pt')  # Thay v√¨ 'n'
```

---

## ‚öôÔ∏è Tham s·ªë quan tr·ªçng

```python
results = model.predict(
    source='image.jpg',      # Ngu·ªìn: ·∫£nh, video, webcam (0), URL
    device=0,                # 0=GPU, 'cpu'=CPU
    conf=0.5,                # Confidence threshold (0-1)
    iou=0.7,                 # IoU threshold cho NMS
    half=True,               # D√πng FP16 (nhanh h∆°n tr√™n GPU)
    imgsz=640,               # K√≠ch th∆∞·ªõc input (320, 640, 1280)
    save=True,               # L∆∞u k·∫øt qu·∫£
    show=False,              # Hi·ªÉn th·ªã k·∫øt qu·∫£
    verbose=True,            # In log
    stream=False,            # Stream mode cho video
    max_det=10,              # S·ªë ng∆∞·ªùi t·ªëi ƒëa detect
)
```

---

## üöÄ T·ªëi ∆∞u hi·ªáu su·∫•t

### TƒÉng t·ªëc ƒë·ªô FPS

```python
# 1. D√πng FP16 (half precision)
results = model(frame, device=0, half=True)

# 2. Gi·∫£m k√≠ch th∆∞·ªõc input
results = model(frame, device=0, imgsz=320)  # Thay v√¨ 640

# 3. D√πng model nh·ªè h∆°n
model = YOLO('yolov8n-pose.pt')  # Nano - nhanh nh·∫•t

# 4. Gi·∫£m confidence threshold
results = model(frame, device=0, conf=0.3)

# 5. Stream mode cho video
results = model.predict(source='video.mp4', device=0, stream=True)
```

### Gi·∫£m VRAM usage

```python
# 1. Gi·∫£m batch size khi train
model.train(data='data.yaml', batch=8)  # Thay v√¨ 16

# 2. Gi·∫£m k√≠ch th∆∞·ªõc input
results = model(frame, imgsz=320)

# 3. D√πng model nh·ªè
model = YOLO('yolov8n-pose.pt')
```

---

## ‚ùå X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p

### L·ªói: CUDA out of memory

**Nguy√™n nh√¢n:** GPU kh√¥ng ƒë·ªß VRAM

**Gi·∫£i ph√°p:**

```python
# 1. D√πng model nh·ªè h∆°n
model = YOLO('yolov8n-pose.pt')

# 2. Gi·∫£m k√≠ch th∆∞·ªõc input
results = model(frame, imgsz=320)

# 3. X√≥a cache
torch.cuda.empty_cache()

# 4. D√πng CPU (ch·∫≠m h∆°n)
results = model(frame, device='cpu')
```

### L·ªói: torch.cuda.is_available() = False

**Nguy√™n nh√¢n:** PyTorch kh√¥ng detect ƒë∆∞·ª£c GPU

**Gi·∫£i ph√°p:**

```bash
# 1. Ki·ªÉm tra driver
nvidia-smi

# 2. G·ª° v√† c√†i l·∫°i PyTorch
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 3. Ki·ªÉm tra l·∫°i
python -c "import torch; print(torch.cuda.is_available())"
```

### L·ªói: Webcam kh√¥ng m·ªü ƒë∆∞·ª£c

**Gi·∫£i ph√°p:**

```python
# Th·ª≠ c√°c camera index kh√°c
cap = cv2.VideoCapture(0)  # Camera 0
cap = cv2.VideoCapture(1)  # Camera 1

# Ki·ªÉm tra camera c√≥ ho·∫°t ƒë·ªông kh√¥ng
if not cap.isOpened():
    print("Cannot open camera")
else:
    print("Camera OK")
```

### L·ªói: Ch·∫°y ch·∫≠m tr√™n GPU

**Ki·ªÉm tra:**

```python
import torch
print(f"Using GPU: {torch.cuda.get_device_name(0)}")
print(f"CUDA version: {torch.version.cuda}")

# ƒê·∫£m b·∫£o d√πng device=0
results = model(frame, device=0)  # KH√îNG d√πng device='cuda' hay device='cpu'
```

---

## üìö Training model c·ªßa b·∫°n (n√¢ng cao)

### Chu·∫©n b·ªã dataset

Dataset ph·∫£i theo format COCO Pose:

```
dataset/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ labels/  # File .txt v·ªõi keypoints
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îî‚îÄ‚îÄ data.yaml
```

File `data.yaml`:

```yaml
path: ./dataset
train: train/images
val: val/images

# Keypoints
kpt_shape: [17, 3] # 17 keypoints, 3 = [x, y, visibility]

# Classes
names:
  0: person
```

### Training

```python
from ultralytics import YOLO

# Load pretrained model
model = YOLO('yolov8n-pose.pt')

# Train
results = model.train(
    data='data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,
    workers=8,
    patience=50,
    save=True,
    project='runs/pose',
    name='my_pose_model'
)
```

---

## üîó T√†i li·ªáu tham kh·∫£o

- **Ultralytics Docs:** https://docs.ultralytics.com/
- **PyTorch:** https://pytorch.org/
- **YOLO Pose:** https://docs.ultralytics.com/tasks/pose/
- **GitHub Issues:** https://github.com/ultralytics/ultralytics/issues

---

## üìù Checklist ho√†n th√†nh

- [ ] C√†i driver NVIDIA v√† ki·ªÉm tra `nvidia-smi`
- [ ] C√†i Python 3.11 v√† th√™m v√†o PATH
- [ ] T·∫°o virtual environment
- [ ] C√†i PyTorch v·ªõi CUDA (version c√≥ `+cu124` ho·∫∑c `+cu118`)
- [ ] Ki·ªÉm tra `torch.cuda.is_available()` = True
- [ ] C√†i Ultralytics v√† OpenCV
- [ ] Test v·ªõi ·∫£nh th√†nh c√¥ng
- [ ] Test v·ªõi webcam th√†nh c√¥ng
- [ ] ƒê·ªçc v√† hi·ªÉu c√°c tham s·ªë ƒëi·ªÅu ch·ªânh

---

## üí° Tips

1. **Lu√¥n k√≠ch ho·∫°t venv tr∆∞·ªõc khi l√†m vi·ªác:**

   ```bash
   venv\Scripts\activate
   ```

2. **D√πng model nh·ªè (nano) cho real-time:**

   ```python
   model = YOLO('yolov8n-pose.pt')
   ```

3. **B·∫≠t FP16 ƒë·ªÉ tƒÉng t·ªëc:**

   ```python
   results = model(frame, device=0, half=True)
   ```

4. **L∆∞u model t·ªët nh·∫•t khi training:**

   ```python
   model.train(data='data.yaml', save_period=10)
   ```

5. **Monitor GPU trong khi ch·∫°y:**
   ```bash
   # Terminal kh√°c
   watch -n 1 nvidia-smi
   ```

---

**Ch√∫c b·∫°n th√†nh c√¥ng! üéâ**

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y ki·ªÉm tra l·∫°i t·ª´ng b∆∞·ªõc trong checklist.
